{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9bfa8ea",
   "metadata": {},
   "source": [
    "# Flight Ticket Price Prediction\n",
    "\n",
    "**Goal:** Predict flight ticket prices using a Random Forest regressor. This notebook is structured as a professional GitHub project: concise explanations, clean code, and reproducible steps.\n",
    "\n",
    "**Dataset columns expected:** `Airline`, `Date_of_Journey`, `Source`, `Destination`, `Route`, `Dep_Time`, `Arrival_Time`, `Duration`, `Total_Stops`, `Additional_Info`, `Price`\n",
    "\n",
    "> **Note:** Upload your dataset file (e.g., `train.csv`) to the working directory before running the notebook. In Google Colab, use the file upload button or mount Google Drive and set the path accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load dataset\n",
    "# Replace 'train.csv' with your filename if different.\n",
    "DATA_PATH = 'train.csv'  # <-- change this if your file has a different name\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Dataset loaded — shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Quick EDA\n",
    "print('Missing values per column:\\n', df.isnull().sum())\n",
    "print('\\nData types:\\n', df.dtypes)\n",
    "print('\\nPrice summary:')\n",
    "print(df['Price'].describe())\n",
    "\n",
    "# Basic plots: price distribution\n",
    "plt.figure()\n",
    "plt.hist(df['Price'].dropna(), bins=40)\n",
    "plt.title('Price distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocessing & Feature Engineering\n",
    "# We'll:\n",
    "# - Parse Date_of_Journey into day and month\n",
    "# - Extract hour/minute from Dep_Time and Arrival_Time\n",
    "# - Convert Duration to total minutes\n",
    "# - Clean Total_Stops (map 'non-stop' or '0 stops' to 0)\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    # Date\n",
    "    df['Date_of_Journey'] = pd.to_datetime(df['Date_of_Journey'], dayfirst=True, errors='coerce')\n",
    "    df['Journey_Day'] = df['Date_of_Journey'].dt.day\n",
    "    df['Journey_Month'] = df['Date_of_Journey'].dt.month\n",
    "\n",
    "    # Times\n",
    "    df['Dep_Time'] = pd.to_datetime(df['Dep_Time'], format='%H:%M', errors='coerce')\n",
    "    df['Dep_Hour'] = df['Dep_Time'].dt.hour\n",
    "    df['Dep_Minute'] = df['Dep_Time'].dt.minute\n",
    "\n",
    "    df['Arrival_Time'] = pd.to_datetime(df['Arrival_Time'], format='%H:%M', errors='coerce')\n",
    "    df['Arrival_Hour'] = df['Arrival_Time'].dt.hour\n",
    "    df['Arrival_Minute'] = df['Arrival_Time'].dt.minute\n",
    "\n",
    "    # Duration: convert strings like '2h 50m' or '50m' to total minutes\n",
    "    def duration_to_mins(x):\n",
    "        if pd.isnull(x):\n",
    "            return np.nan\n",
    "        parts = x.split()\n",
    "        mins = 0\n",
    "        for p in parts:\n",
    "            if 'h' in p:\n",
    "                try:\n",
    "                    mins += int(p.replace('h',''))*60\n",
    "                except:\n",
    "                    pass\n",
    "            elif 'm' in p:\n",
    "                try:\n",
    "                    mins += int(p.replace('m',''))\n",
    "                except:\n",
    "                    pass\n",
    "        return mins\n",
    "    df['Duration_mins'] = df['Duration'].apply(duration_to_mins)\n",
    "\n",
    "    # Total stops: extract digits\n",
    "    df['Total_Stops_num'] = df['Total_Stops'].astype(str).str.extract('(\\d+)')\n",
    "    df['Total_Stops_num'] = df['Total_Stops_num'].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "df_processed = preprocess(df)\n",
    "print('After feature engineering — columns:', df_processed.columns.tolist())\n",
    "df_processed[['Journey_Day','Journey_Month','Dep_Hour','Arrival_Hour','Duration_mins','Total_Stops_num']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prepare features and target\n",
    "FEATURES = ['Airline','Source','Destination','Journey_Day','Journey_Month','Dep_Hour','Dep_Minute','Arrival_Hour','Arrival_Minute','Duration_mins','Total_Stops_num']\n",
    "TARGET = 'Price'\n",
    "\n",
    "data = df_processed[FEATURES + [TARGET]].dropna()\n",
    "X = data[FEATURES]\n",
    "y = data[TARGET]\n",
    "\n",
    "print('Final dataset for modeling — X shape:', X.shape, 'y shape:', y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train/test split and modeling pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Categorical and numeric handling\n",
    "cat_cols = ['Airline','Source','Destination']\n",
    "num_cols = ['Journey_Day','Journey_Month','Dep_Hour','Dep_Minute','Arrival_Hour','Arrival_Minute','Duration_mins','Total_Stops_num']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "        ('num', 'passthrough', num_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "pipe = Pipeline(steps=[('pre', preprocessor), ('model', model)])\n",
    "\n",
    "# Fit\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluation\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f'R2 score: {r2:.4f}')\n",
    "print(f'MAE: {mae:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')\n",
    "\n",
    "# Scatter plot: Actual vs Predicted\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs Predicted Ticket Price')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2355ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature importance (approximate)\n",
    "pre = pipe.named_steps['pre']\n",
    "cat_features = pre.named_transformers_['cat'].get_feature_names_out(['Airline','Source','Destination'])\n",
    "num_cols = ['Journey_Day','Journey_Month','Dep_Hour','Dep_Minute','Arrival_Hour','Arrival_Minute','Duration_mins','Total_Stops_num']\n",
    "all_features = list(cat_features) + num_cols\n",
    "\n",
    "importances = pipe.named_steps['model'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=all_features).sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(feat_imp.index, feat_imp.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Top feature importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Top features:\\n', feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56dcaf",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "- We built a Random Forest model to predict flight ticket prices using common flight features.\n",
    "- Primary evaluation: **R² score**, **MAE**, and **RMSE** (printed above).\n",
    "- Visual checks: Actual vs Predicted scatter plot and feature importance chart.\n",
    "\n",
    "### Next steps / improvements\n",
    "- Hyperparameter tuning (GridSearchCV) to further improve R².\n",
    "- More advanced feature engineering (e.g., holiday flags, seasonal features).\n",
    "- Try gradient boosting (XGBoost / LightGBM) for potential performance gains.\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook generated on <class 'datetime.datetime'>.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
